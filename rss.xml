<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bounded Rationality</title><link>http://satisficing.briankeng.com/</link><description>Understanding programming, data, and math to a satisfactory degree.</description><atom:link rel="self" type="application/rss+xml" href="http://satisficing.briankeng.com/rss.xml"></atom:link><language>en</language><lastBuildDate>Tue, 13 Dec 2016 13:48:53 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Lagrange Multipliers</title><link>http://satisficing.briankeng.com/posts/lagrange-multipliers/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is going to be about finding the maxima or minima of a function
subject to some constraints.  This is usually introduced in a multivariate
calculus course, unfortunately (or fortunately?) I never got the chance to take
a multivariate calculus course that covered this topic.  In my undergraduate class, computer
engineers only took three half year engineering calculus courses, and the
&lt;a class="reference external" href="http://www.ucalendar.uwaterloo.ca/1617/COURSE/course-ECE.html#ECE206"&gt;fourth one&lt;/a&gt;
(for electrical engineers) seems to have covered other basic multivariate
calculus topics such as all the various theorems such as Green's, Gauss', Stokes' (I
could be wrong though, I never did take that course!).  You know what I always imagined Newton
saying, "It's never too late to learn multivariate calculus!".&lt;/p&gt;
&lt;p&gt;In that vein, this post will discuss one widely used method for finding optima
subject to constraints: Lagrange multipliers.  The concepts
behind it are actually quite intuitive once we come up with the right analogue
in physical reality, so as usual we'll start there.  We'll work through some
problems and hopefully by the end of this post, this topic won't seem as
mysterious anymore &lt;a class="footnote-reference" href="http://satisficing.briankeng.com/posts/lagrange-multipliers/#id3" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/lagrange-multipliers/"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>calculus</category><category>lagrange multipliers</category><category>mathjax</category><guid>http://satisficing.briankeng.com/posts/lagrange-multipliers/</guid><pubDate>Tue, 13 Dec 2016 12:48:31 GMT</pubDate></item><item><title>The Expectation-Maximization Algorithm</title><link>http://satisficing.briankeng.com/posts/the-expectation-maximization-algorithm/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is going to talk about a widely used method to find the
maximum likelihood (MLE) or maximum a posteriori (MAP) estimate of parameters
in latent variable models called the Expectation-Maximization algorithm.  You
have probably heard about the most famous variant of this algorithm called the
k-means algorithm for clustering.
Even though it's so ubiquitous, whenever I've tried to understand &lt;em&gt;why&lt;/em&gt; this
algorithm works, I never quite got the intuition right.  Now that I've taken
the time to work through the math, I'm going to &lt;em&gt;attempt&lt;/em&gt; to explain the
algorithm hopefully with a bit more clarity.  We'll start by going back to the
basics with latent variable models and the likelihood functions, then moving on
to showing the math with a simple Gaussian mixture model &lt;a class="footnote-reference" href="http://satisficing.briankeng.com/posts/the-expectation-maximization-algorithm/#id5" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/the-expectation-maximization-algorithm/"&gt;Read more…&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>expectation-maximization</category><category>gaussian mixture models</category><category>latent variables</category><category>mathjax</category><guid>http://satisficing.briankeng.com/posts/the-expectation-maximization-algorithm/</guid><pubDate>Fri, 07 Oct 2016 12:47:47 GMT</pubDate></item><item><title>A Probabilistic Interpretation of Regularization</title><link>http://satisficing.briankeng.com/posts/probabilistic-interpretation-of-regularization/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is going to look at a probabilistic (Bayesian) interpretation of
regularization.  We'll take a look at both L1 and L2 regularization in the
context of ordinary linear regression.  The discussion will start off
with a quick introduction to regularization, followed by a back-to-basics
explanation starting with the maximum likelihood estimate (MLE), then on to the
maximum a posteriori estimate (MAP), and finally playing around with priors to
end up with L1 and L2 regularization.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/probabilistic-interpretation-of-regularization/"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Bayesian</category><category>mathjax</category><category>probability</category><category>regularization</category><guid>http://satisficing.briankeng.com/posts/probabilistic-interpretation-of-regularization/</guid><pubDate>Mon, 29 Aug 2016 12:52:33 GMT</pubDate></item><item><title>Beyond Collaborative Filtering</title><link>http://satisficing.briankeng.com/posts/beyond-collaborative-filtering/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;I wrote a couple of posts about some of the work on recommendation systems and
collaborative filtering that we're doing at my job as a Data Scientist at
&lt;a class="reference external" href="http://www.rubikloud.com"&gt;Rubikloud&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://rubikloud.com/labs/data-science/beyond-collaborative-filtering/"&gt;Beyond Collaborative Filtering (Part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://rubikloud.com/labs/data-science/beyond-collaborative-filtering-part-2/"&gt;Beyond Collaborative Filtering (Part 2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's a blurb:&lt;/p&gt;
&lt;blockquote&gt;
Here at Rubikloud, a big focus of our data science team is empowering retailers
in delivering personalized one-to-one communications with their customers. A
big aspect of personalization is recommending products and services that are
tailored to a customer’s wants and needs. Naturally, recommendation systems are
an active research area in machine learning with practical large scale
deployments from companies such as Netflix and Spotify. In Part 1 of this
series, I’ll describe the unique challenges that we have faced in building a
retail specific product recommendation system and outline one of the main
components of our recommendation system: a collaborative filtering algorithm.
In Part 2, I’ll follow up with several useful applications of collaborative
filtering and end by highlighting some of its limitations.&lt;/blockquote&gt;
&lt;p&gt;Hope you like it!&lt;/p&gt;&lt;/div&gt;</description><category>Collaborative Filtering</category><category>Machine Learning</category><category>Recommendation Systems</category><guid>http://satisficing.briankeng.com/posts/beyond-collaborative-filtering/</guid><pubDate>Sat, 11 Jun 2016 22:00:34 GMT</pubDate></item><item><title>A Probabilistic View of Linear Regression</title><link>http://satisficing.briankeng.com/posts/a-probabilistic-view-of-regression/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;One thing that I always disliked about introductory material to linear
regression is how randomness is explained.  The explanations always
seemed unintuitive because, as I have frequently seen it, they appear as an
after thought rather than the central focus of the model.
In this post, I'm going to try to
take another approach to building an ordinary linear regression model starting
from a probabilistic point of view (which is pretty much just a Bayesian view).
After the general idea is established, I'll modify the model a bit and end up
with a Poisson regression using the exact same principles showing how
generalized linear models aren't any more complicated.  Hopefully, this will
help explain the "randomness" in linear regression in a more intuitive way.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/a-probabilistic-view-of-regression/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Bayesian</category><category>logistic</category><category>mathjax</category><category>Poisson</category><category>probability</category><category>regression</category><guid>http://satisficing.briankeng.com/posts/a-probabilistic-view-of-regression/</guid><pubDate>Sun, 15 May 2016 00:43:05 GMT</pubDate></item><item><title>Normal Approximation to the Posterior Distribution</title><link>http://satisficing.briankeng.com/posts/normal-approximations-to-the-posterior-distribution/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post, I'm going to write about how the ever versatile normal distribution can be used to approximate a Bayesian posterior distribution.  Unlike some other normal approximations, this is &lt;em&gt;not&lt;/em&gt; a direct application of the central limit theorem.  The result has a straight forward proof using Laplace's Method whose main ideas I will attempt to present.  I'll also simulate a simple scenario to see how it works in practice.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/normal-approximations-to-the-posterior-distribution/"&gt;Read more…&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Bayesian</category><category>normal distribution</category><category>posterior</category><category>prior</category><category>probability</category><category>sampling</category><guid>http://satisficing.briankeng.com/posts/normal-approximations-to-the-posterior-distribution/</guid><pubDate>Sat, 02 Apr 2016 19:22:54 GMT</pubDate></item><item><title>The Empirical Distribution Function</title><link>http://satisficing.briankeng.com/posts/the-empirical-distribution-function/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This post is going to look at a useful non-parametric method for estimating the cumulative distribution function (CDF) of a random variable called the &lt;a href="https://en.wikipedia.org/wiki/Empirical_distribution_function"&gt;empirical distribution function&lt;/a&gt; (sometimes called the empirical CDF).  We'll talk a bit about the mechanics of computing it, some theory about its confidence intervals and also do some simulations to gain some intuition about how it behaves.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/the-empirical-distribution-function/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CDF</category><category>confidence bands</category><category>confidence intervals</category><category>empirical distribution function</category><guid>http://satisficing.briankeng.com/posts/the-empirical-distribution-function/</guid><pubDate>Sun, 13 Mar 2016 01:08:21 GMT</pubDate></item><item><title>Elementary Statistics for Direct Marketing</title><link>http://satisficing.briankeng.com/posts/normal-difference-distribution/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is going to look at some elementary statistics for direct marketing.
Most of the techniques are direct applications of topics learned in a first
year statistics course hence the "elementary".  I'll start off by covering some
background and terminology on the direct marketing and then introduce some of
the statistical inference techniques that are commonly used.  As usual, I'll
mix in some theory where appropriate to build some intuition.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/normal-difference-distribution/"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>direct marketing</category><category>mathjax</category><category>normal</category><category>probability</category><category>sample size</category><guid>http://satisficing.briankeng.com/posts/normal-difference-distribution/</guid><pubDate>Sun, 28 Feb 2016 01:40:41 GMT</pubDate></item><item><title>A Primer on Statistical Inference and Hypothesis Testing</title><link>http://satisficing.briankeng.com/posts/hypothesis-testing/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is about some fundamental concepts in classical (or frequentist)
statistics: inference and hypothesis testing.  A while back, I came to the
realization that I didn't have a good intuition of these concepts (at least
not to my liking) beyond the mechanical nature of applying them.
What was missing was how they related to a probabilistic view of the subject.
This bothered me since having a good intuition about a subject is
probably the most useful (and fun!) part of learning a subject.  So this post
is a result of my re-education on these topics.  Enjoy!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/hypothesis-testing/"&gt;Read more…&lt;/a&gt; (19 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>frequentist statistics</category><category>hypothesis testing</category><category>mathjax</category><category>models</category><category>p-values</category><category>statistical inference</category><guid>http://satisficing.briankeng.com/posts/hypothesis-testing/</guid><pubDate>Sat, 09 Jan 2016 16:22:26 GMT</pubDate></item><item><title>Markov Chain Monte Carlo Methods, Rejection Sampling and the Metropolis-Hastings Algorithm</title><link>http://satisficing.briankeng.com/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post, I'm going to continue on the same theme from the last post: &lt;a href="http://satisficing.briankeng.com/posts/sampling-from-a-normal-distribution"&gt;random sampling&lt;/a&gt;.  We're going to look at two methods for sampling a distribution: rejection sampling and Markov Chain Monte Carlo Methods (MCMC) using the Metropolis Hastings algorithm.  As usual, I'll be providing a mix of intuitive explanations, theory and some examples with code.  Hopefully, this will help explain a relatively straight-forward topic that is frequently presented in a complex way.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Markov Chain</category><category>MCMC</category><category>Metropolis-Hastings</category><category>Monte Carlo</category><category>probability</category><category>rejection sampling</category><category>sampling</category><guid>http://satisficing.briankeng.com/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/</guid><pubDate>Sun, 13 Dec 2015 20:05:56 GMT</pubDate></item></channel></rss>